{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
      "     ---------------------------------------- 0.0/130.7 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/130.7 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/130.7 kB ? eta -:--:--\n",
      "     ----------- ------------------------- 41.0/130.7 kB 245.8 kB/s eta 0:00:01\n",
      "     -------------------- ---------------- 71.7/130.7 kB 357.2 kB/s eta 0:00:01\n",
      "     --------------------------------- -- 122.9/130.7 kB 554.9 kB/s eta 0:00:01\n",
      "     --------------------------------- -- 122.9/130.7 kB 554.9 kB/s eta 0:00:01\n",
      "     --------------------------------- -- 122.9/130.7 kB 554.9 kB/s eta 0:00:01\n",
      "     --------------------------------- -- 122.9/130.7 kB 554.9 kB/s eta 0:00:01\n",
      "     --------------------------------- -- 122.9/130.7 kB 554.9 kB/s eta 0:00:01\n",
      "     ------------------------------------ 130.7/130.7 kB 248.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\harit\\anaconda3\\envs\\kidney\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\harit\\anaconda3\\envs\\kidney\\lib\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\harit\\anaconda3\\envs\\kidney\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\harit\\anaconda3\\envs\\kidney\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\harit\\anaconda3\\envs\\kidney\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2023.12.25-cp38-cp38-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     --------------------------- ---------- 30.7/42.0 kB 435.7 kB/s eta 0:00:01\n",
      "     -------------------------------------  41.0/42.0 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------------------  41.0/42.0 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------------------  41.0/42.0 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------------------  41.0/42.0 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------------------  41.0/42.0 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------------------  41.0/42.0 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------------------  41.0/42.0 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------------------  41.0/42.0 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------------------  41.0/42.0 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------------------  41.0/42.0 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------------------  41.0/42.0 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------------------  41.0/42.0 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------------------  41.0/42.0 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------------------  41.0/42.0 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------------------  41.0/42.0 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------------------  41.0/42.0 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------------------  41.0/42.0 kB 487.6 kB/s eta 0:00:01\n",
      "     --------------------------------------- 42.0/42.0 kB 35.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\harit\\anaconda3\\envs\\kidney\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Downloading tokenizers-0.15.2-cp38-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\harit\\anaconda3\\envs\\kidney\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\harit\\anaconda3\\envs\\kidney\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\harit\\anaconda3\\envs\\kidney\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\harit\\anaconda3\\envs\\kidney\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\harit\\anaconda3\\envs\\kidney\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\harit\\anaconda3\\envs\\kidney\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harit\\anaconda3\\envs\\kidney\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\harit\\anaconda3\\envs\\kidney\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harit\\anaconda3\\envs\\kidney\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "   ---------------------------------------- 0.0/8.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/8.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/8.5 MB 2.5 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.2/8.5 MB 2.0 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.3/8.5 MB 2.0 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.5/8.5 MB 2.0 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.5/8.5 MB 1.9 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.6/8.5 MB 1.9 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.6/8.5 MB 1.8 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.6/8.5 MB 1.8 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.6/8.5 MB 1.8 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.6/8.5 MB 1.8 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.6/8.5 MB 1.8 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.0/8.5 MB 1.6 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.0/8.5 MB 1.5 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.1/8.5 MB 1.5 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.1/8.5 MB 1.4 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.1/8.5 MB 1.4 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.3/8.5 MB 1.4 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.3/8.5 MB 1.4 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.4/8.5 MB 1.4 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.5/8.5 MB 1.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.6/8.5 MB 1.5 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.7/8.5 MB 1.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.7/8.5 MB 1.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.8/8.5 MB 1.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.9/8.5 MB 1.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.9/8.5 MB 1.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.9/8.5 MB 1.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.9/8.5 MB 1.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.9/8.5 MB 1.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.9/8.5 MB 1.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.1/8.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.2/8.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.2/8.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.3/8.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.4/8.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.4/8.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.4/8.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.4/8.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.4/8.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 2.7/8.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.8/8.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.9/8.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.9/8.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 3.0/8.5 MB 1.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.0/8.5 MB 1.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.0/8.5 MB 1.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.0/8.5 MB 1.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.0/8.5 MB 1.2 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.1/8.5 MB 1.2 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.1/8.5 MB 1.2 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 3.2/8.5 MB 1.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 3.3/8.5 MB 1.2 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 3.3/8.5 MB 1.2 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 3.4/8.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 3.5/8.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 3.5/8.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 3.6/8.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 3.6/8.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 3.6/8.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 3.7/8.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 3.7/8.5 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 3.8/8.5 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 3.8/8.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 3.8/8.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 3.8/8.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 3.8/8.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 3.8/8.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 3.8/8.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 3.8/8.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 3.8/8.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 3.8/8.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 3.8/8.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 4.0/8.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 4.0/8.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 4.0/8.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 4.0/8.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 4.1/8.5 MB 1.0 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 4.2/8.5 MB 1.0 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 4.2/8.5 MB 1.0 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 4.3/8.5 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 4.3/8.5 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 4.3/8.5 MB 1.0 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 4.3/8.5 MB 1.0 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 4.3/8.5 MB 1.0 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 4.4/8.5 MB 1.0 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 4.4/8.5 MB 1.0 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 4.5/8.5 MB 1.0 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 4.5/8.5 MB 1.0 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 4.5/8.5 MB 1.0 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 4.5/8.5 MB 1.0 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 4.5/8.5 MB 1.0 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 4.7/8.5 MB 1.0 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 4.8/8.5 MB 1.0 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 4.9/8.5 MB 1.0 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 4.9/8.5 MB 1.0 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 5.0/8.5 MB 1.0 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 5.0/8.5 MB 1.0 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 5.1/8.5 MB 1.0 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 5.2/8.5 MB 1.0 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 5.2/8.5 MB 1.0 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 5.3/8.5 MB 1.0 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 5.3/8.5 MB 1.0 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 5.4/8.5 MB 1.0 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 5.5/8.5 MB 1.0 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 5.5/8.5 MB 1.0 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 5.5/8.5 MB 1.0 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 5.6/8.5 MB 1.0 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 5.6/8.5 MB 1.0 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 5.6/8.5 MB 1.0 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 5.6/8.5 MB 1.0 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 5.6/8.5 MB 1.0 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 5.7/8.5 MB 1.0 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 5.7/8.5 MB 1.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 5.8/8.5 MB 1.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 5.9/8.5 MB 1.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 5.9/8.5 MB 1.0 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 6.0/8.5 MB 1.0 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 6.1/8.5 MB 1.0 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 6.2/8.5 MB 1.0 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 6.2/8.5 MB 1.0 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 6.3/8.5 MB 1.0 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 6.5/8.5 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 6.5/8.5 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 6.6/8.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 6.7/8.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 6.7/8.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 6.8/8.5 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 6.9/8.5 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 6.9/8.5 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.0/8.5 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.0/8.5 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.0/8.5 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 7.1/8.5 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 7.1/8.5 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 7.1/8.5 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 7.1/8.5 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 7.2/8.5 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 7.2/8.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 7.3/8.5 MB 1.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 7.3/8.5 MB 1.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 7.4/8.5 MB 1.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 7.4/8.5 MB 1.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 7.5/8.5 MB 1.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 7.5/8.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.6/8.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.6/8.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.6/8.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.6/8.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.6/8.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.6/8.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.6/8.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.6/8.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.6/8.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.6/8.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.6/8.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.6/8.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.6/8.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.6/8.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.8/8.5 MB 981.2 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.8/8.5 MB 981.2 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.8/8.5 MB 973.5 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.8/8.5 MB 966.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.8/8.5 MB 961.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.9/8.5 MB 959.8 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.9/8.5 MB 959.8 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.9/8.5 MB 957.0 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.9/8.5 MB 948.2 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.0/8.5 MB 950.6 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.0/8.5 MB 947.2 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.0/8.5 MB 947.2 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.0/8.5 MB 947.2 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.0/8.5 MB 947.2 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.0/8.5 MB 932.5 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.1/8.5 MB 931.0 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.1/8.5 MB 927.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.2/8.5 MB 928.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.2/8.5 MB 928.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.2/8.5 MB 927.7 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.3/8.5 MB 927.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.3/8.5 MB 928.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.4/8.5 MB 927.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.4/8.5 MB 924.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 926.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 926.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 925.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 922.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.5/8.5 MB 687.9 kB/s eta 0:00:00\n",
      "Downloading regex-2023.12.25-cp38-cp38-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.5 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 92.2/269.5 kB 2.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 122.9/269.5 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 163.8/269.5 kB 1.1 MB/s eta 0:00:01\n",
      "   --------------------------- ---------- 194.6/269.5 kB 908.0 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 194.6/269.5 kB 908.0 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 194.6/269.5 kB 908.0 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 194.6/269.5 kB 908.0 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 245.8/269.5 kB 602.4 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 245.8/269.5 kB 602.4 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 245.8/269.5 kB 602.4 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 245.8/269.5 kB 602.4 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 245.8/269.5 kB 602.4 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 245.8/269.5 kB 602.4 kB/s eta 0:00:01\n",
      "   -------------------------------------  266.2/269.5 kB 390.2 kB/s eta 0:00:01\n",
      "   -------------------------------------  266.2/269.5 kB 390.2 kB/s eta 0:00:01\n",
      "   -------------------------------------  266.2/269.5 kB 390.2 kB/s eta 0:00:01\n",
      "   -------------------------------------  266.2/269.5 kB 390.2 kB/s eta 0:00:01\n",
      "   -------------------------------------  266.2/269.5 kB 390.2 kB/s eta 0:00:01\n",
      "   -------------------------------------  266.2/269.5 kB 390.2 kB/s eta 0:00:01\n",
      "   -------------------------------------  266.2/269.5 kB 390.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- 269.5/269.5 kB 251.5 kB/s eta 0:00:00\n",
      "Downloading tokenizers-0.15.2-cp38-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.2 MB 330.3 kB/s eta 0:00:07\n",
      "    --------------------------------------- 0.0/2.2 MB 330.3 kB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.1/2.2 MB 365.7 kB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.1/2.2 MB 306.3 kB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.1/2.2 MB 262.6 kB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.1/2.2 MB 327.7 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.2/2.2 MB 364.0 kB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.2/2.2 MB 364.0 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.2/2.2 MB 347.1 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.2/2.2 MB 355.7 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.2/2.2 MB 355.7 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.2/2.2 MB 355.7 kB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 0.2/2.2 MB 305.9 kB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 0.2/2.2 MB 314.0 kB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 0.3/2.2 MB 327.9 kB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 0.3/2.2 MB 345.7 kB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 0.3/2.2 MB 345.7 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 0.3/2.2 MB 355.4 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 0.3/2.2 MB 355.4 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 0.3/2.2 MB 355.4 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 0.3/2.2 MB 355.4 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 0.3/2.2 MB 355.4 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 0.3/2.2 MB 355.4 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 0.3/2.2 MB 355.4 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 0.3/2.2 MB 355.4 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 0.3/2.2 MB 355.4 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 0.3/2.2 MB 355.4 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 0.3/2.2 MB 355.4 kB/s eta 0:00:06\n",
      "   --------- ------------------------------ 0.5/2.2 MB 367.3 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 0.6/2.2 MB 367.9 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 0.6/2.2 MB 367.1 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 0.6/2.2 MB 359.2 kB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 0.6/2.2 MB 358.1 kB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 0.6/2.2 MB 362.8 kB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 0.6/2.2 MB 362.8 kB/s eta 0:00:05\n",
      "   ------------ --------------------------- 0.7/2.2 MB 365.9 kB/s eta 0:00:05\n",
      "   ------------- -------------------------- 0.7/2.2 MB 372.9 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 0.8/2.2 MB 379.8 kB/s eta 0:00:04\n",
      "   -------------- ------------------------- 0.8/2.2 MB 389.1 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 0.8/2.2 MB 405.2 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 0.9/2.2 MB 413.9 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 0.9/2.2 MB 417.6 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 0.9/2.2 MB 416.7 kB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 1.0/2.2 MB 421.7 kB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 1.0/2.2 MB 421.7 kB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 1.0/2.2 MB 416.3 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 1.0/2.2 MB 418.2 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 1.0/2.2 MB 420.2 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 1.1/2.2 MB 428.7 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 1.1/2.2 MB 430.2 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 1.1/2.2 MB 434.4 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 1.2/2.2 MB 442.2 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 1.2/2.2 MB 444.6 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 1.2/2.2 MB 444.6 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 1.2/2.2 MB 444.6 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 1.2/2.2 MB 434.5 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 1.3/2.2 MB 434.5 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 439.3 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 1.3/2.2 MB 439.2 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 1.4/2.2 MB 449.3 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 1.4/2.2 MB 446.9 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.5/2.2 MB 455.2 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.5/2.2 MB 458.4 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.5/2.2 MB 465.5 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 1.5/2.2 MB 465.0 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 1.5/2.2 MB 459.5 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 463.0 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.6/2.2 MB 461.8 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.6/2.2 MB 457.4 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.6/2.2 MB 454.2 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.7/2.2 MB 459.6 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 1.7/2.2 MB 458.3 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 1.7/2.2 MB 462.7 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.2 MB 465.1 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.2 MB 470.8 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.2 MB 474.3 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.2 MB 474.3 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.2 MB 474.3 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.2 MB 474.3 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.0/2.2 MB 480.8 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.0/2.2 MB 480.4 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.0/2.2 MB 487.3 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.1/2.2 MB 489.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.1/2.2 MB 491.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.2 MB 497.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 496.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 500.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 500.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 500.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 500.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 500.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 500.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 500.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 464.1 kB/s eta 0:00:00\n",
      "Installing collected packages: regex, tokenizers, transformers\n",
      "Successfully installed regex-2023.12.25 tokenizers-0.15.2 transformers-4.38.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harit\\anaconda3\\envs\\kidney\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KidneyDataset(Dataset):\n",
    "    def __init__(self, root_dir, feature_extractor):\n",
    "        self.root_dir = root_dir\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.classes = ['Cyst', 'Normal', 'Stone', 'Tumour']\n",
    "        self.data = []\n",
    "        for idx, cls in enumerate(self.classes):\n",
    "            path = os.path.join(root_dir, cls)\n",
    "            for img in os.listdir(path):\n",
    "                self.data.append((os.path.join(path, img), idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = torchvision.io.read_image(img_path)\n",
    "        image = self.feature_extractor(images=image, return_tensors=\"pt\").pixel_values[0]\n",
    "        return image, label\n",
    "\n",
    "root_dir = 'C:\\\\final_project\\\\comprehensive_kidney_disease_classification\\\\artifacts\\\\data_ingestion\\\\kidney-ct-scan-image'\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "dataset = KidneyDataset(root_dir, feature_extractor)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import ViTForImageClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "class ViTClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ViTClassifier, self).__init__()\n",
    "        self.vit = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "        self.vit.classifier = nn.Linear(self.vit.classifier.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vit(pixel_values=x).logits\n",
    "        return x\n",
    "\n",
    "model = ViTClassifier(num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTClassifier(\n",
       "  (vit): ViTForImageClassification(\n",
       "    (vit): ViTModel(\n",
       "      (embeddings): ViTEmbeddings(\n",
       "        (patch_embeddings): ViTPatchEmbeddings(\n",
       "          (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (encoder): ViTEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x ViTLayer(\n",
       "            (attention): ViTAttention(\n",
       "              (attention): ViTSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): ViTSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): ViTIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): ViTOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "    (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'type_check' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m  \n\u001b[0;32m      2\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\harit\\anaconda3\\envs\\kidney\\lib\\site-packages\\torch\\__init__.py:1215\u001b[0m\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;66;03m# Define Storage and Tensor classes\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[1;32m-> 1215\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstorage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _StorageBase, TypedStorage, _LegacyStorage, UntypedStorage, _warn_typed_storage_removal\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;66;03m# NOTE: New <type>Storage classes should never be added. When adding a new\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;66;03m# dtype, use torch.storage.TypedStorage directly.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mByteStorage\u001b[39;00m(_LegacyStorage):\n",
      "File \u001b[1;32mc:\\Users\\harit\\anaconda3\\envs\\kidney\\lib\\site-packages\\torch\\storage.py:14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     HAS_NUMPY \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\harit\\anaconda3\\envs\\kidney\\lib\\site-packages\\numpy\\__init__.py:143\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lib\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# NOTE: to be revisited following future namespace cleanup.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# See gh-14454 and gh-15672 for discussion.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\harit\\anaconda3\\envs\\kidney\\lib\\site-packages\\numpy\\lib\\__init__.py:44\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_multiarray_umath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tracemalloc_domain\n\u001b[0;32m     43\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memath\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmath\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtracemalloc_domain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArrayterator\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 44\u001b[0m __all__ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtype_check\u001b[49m\u001b[38;5;241m.\u001b[39m__all__\n\u001b[0;32m     45\u001b[0m __all__ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m index_tricks\u001b[38;5;241m.\u001b[39m__all__\n\u001b[0;32m     46\u001b[0m __all__ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m function_base\u001b[38;5;241m.\u001b[39m__all__\n",
      "\u001b[1;31mNameError\u001b[0m: name 'type_check' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim  \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accuracies = []\n",
    "num_epochs = 25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Loss: {epoch_loss}, Accuracy: {epoch_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      2\u001b[0m all_preds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m all_labels \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
    "print(f\"Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\")\n",
    "print(classification_report(all_labels, all_preds, target_names=['Cyst', 'Normal', 'Stone', 'Tumour']))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Model': ['ViTClassifier'],\n",
    "    'Accuracy': [accuracy],\n",
    "    'Precision': [precision],\n",
    "    'Recall': [recall],\n",
    "    'F1 Score': [f1]\n",
    "})\n",
    "df.to_csv('model_performance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"confusion_matrix.csv\", conf_matrix, delimiter=\",\", fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'vit_kidney_disease_classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Assuming `conf_matrix` is your confusion matrix obtained from the evaluation step\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Cyst', 'Normal', 'Stone', 'Tumor'], yticklabels=['Cyst', 'Normal', 'Stone', 'Tumor'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/kaggle/working/vit_kidney_disease_classifier.pth'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy and other metrics if needed\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(all_labels, all_preds, target_names=['Cyst', 'Normal', 'Stone', 'Tumor']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate classification metrics\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
    "\n",
    "# Print metrics to console\n",
    "print(f'Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}')\n",
    "\n",
    "# Create a DataFrame and save it to a CSV file\n",
    "report_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Score': [accuracy, precision, recall, f1]\n",
    "})\n",
    "report_df.to_csv('/kaggle/working/classification_report.csv', index=False)\n",
    "\n",
    "# Calculate and plot the confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Cyst', 'Normal', 'Stone', 'Tumor'], yticklabels=['Cyst', 'Normal', 'Stone', 'Tumor'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.savefig('/kaggle/working/confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kidney",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
